{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***Importing libraries***\n",
    "\n",
    "#Math tools\n",
    "import numpy as np\n",
    "\n",
    "#Data science tools\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#OS tools\n",
    "import os\n",
    "\n",
    "#Image processing tools\n",
    "import cv2 \n",
    "\n",
    "#Plotting tools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Error definition ###\n",
    "def error_fn(y_true, y_pred):\n",
    "    error = 0;\n",
    "    for i in range(0,len(y_true)):\n",
    "        if y_true[i] != y_pred[i]:\n",
    "            error += 1; #Counts the number of misclassifications\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the number of classes and images to use\n",
    "n_classes = 10;\n",
    "n_figs = 700;\n",
    "\n",
    "#Specifying the total number of classes and images avaialble\n",
    "N_classes = 45;\n",
    "N_figs = 700;\n",
    "\n",
    "#Randomly choosing the classes and figures to analyze\n",
    "class_idx = np.random.permutation(N_classes)[:n_classes];\n",
    "fig_idx = np.random.permutation(N_figs)[:n_figs]\n",
    "#These two lines above generate different choices each time they're executed unless the random seed is reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the path\n",
    "PROJECT_ROOT_DIR = '..'\n",
    "DATASET_FOLDER = 'training_data'\n",
    "DATASET_PATH = os.path.join(PROJECT_ROOT_DIR,DATASET_FOLDER)\n",
    "\n",
    "\n",
    "#Reading the folders tree\n",
    "classes_all = sorted(os.listdir(DATASET_PATH));\n",
    "classes_all.remove('summary'); #Removes the summary file\n",
    "N_classes = len(classes_all)\n",
    "if n_classes > 0 and n_classes <= N_classes:\n",
    "    classes = [classes_all[idx] for idx in class_idx]\n",
    "else:\n",
    "    print('Wrong number of classes requested')\n",
    "    raise SystemExit(0)\n",
    "    \n",
    "#Reading the figures\n",
    "figs = [];\n",
    "for folder in classes:\n",
    "    CLASS_PATH = os.path.join(DATASET_PATH, folder);\n",
    "    figs_names_all = sorted(os.listdir(CLASS_PATH));\n",
    "    if n_figs > 0 and n_figs <= N_figs:\n",
    "        figs_names = [figs_names_all[idx] for idx in fig_idx]\n",
    "        FIGS_PATHS = [os.path.join(CLASS_PATH, fig) for fig in figs_names]\n",
    "        figs_i = [cv2.imread(PATH,0) for PATH in FIGS_PATHS]; #cv2.imread with flag 0 reads the image in grayscale\n",
    "        figs.append(figs_i)\n",
    "    else:\n",
    "        print('Wrong number of figures requested')\n",
    "        raise SystemExit(0)\n",
    "\n",
    "#Converting into a numpy array\n",
    "figs = np.array(figs);\n",
    "print('figs.shape')\n",
    "print(figs.shape)\n",
    "\n",
    "##***Output***\n",
    "# figs: Multidimensional numpy array containing all read images. First dimension corresponds to class and second dimension to figures. \n",
    "#Each figure is a multidimensional array itself of 256x256 pixels and only the greyscale channel: int(0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Shows the names of the chosen classes and their corresponding indexes in figs\n",
    "print('Chosen classes:')\n",
    "print(list(enumerate(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing some of the data\n",
    "fig_test = figs[0][0];\n",
    "plt.imshow(fig_test, cmap = mpl.cm.binary); plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linearizing the input data\n",
    "X = figs.reshape([n_classes*n_figs, 256, 256]); #Inputs\n",
    "y = np.zeros([n_classes, n_figs], dtype=int);\n",
    "for i in range (n_classes):\n",
    "    for j in range(n_figs):\n",
    "        y[i,j] = i;\n",
    "y = y.reshape([n_classes*n_figs]); #Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the input data\n",
    "idx_random = np.random.permutation(len(X));\n",
    "X = X[idx_random,:,:];\n",
    "y = y[idx_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing some of the data\n",
    "idx = 5;\n",
    "X_sample = X[idx];\n",
    "plt.imshow(X_sample, cmap = mpl.cm.binary); plt.axis(\"off\");\n",
    "print(y[idx])\n",
    "print(classes[y[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the dataset to a 2D array\n",
    "X = X.reshape(-1, 256*256);\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75, random_state=0)\n",
    "N_train = len(X_train)\n",
    "N_test = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the models\n",
    "C = 1  # SVM regularization parameter\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.SVC(kernel='poly', degree=2, gamma='auto', C=C),\n",
    "          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C))\n",
    "titles = ('SVM with linear kernel',\n",
    "          'SVM with polynomial (degree 2) kernel',\n",
    "          'SVM with polynomial (degree 3) kernel',\n",
    "          'SVM with RBF kernel')\n",
    "#Training \n",
    "models = (clf.fit(X_train, y_train) for clf in models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0;\n",
    "error = np.zeros(len(titles))\n",
    "for clf in models:       \n",
    "    y_pred = clf.predict(X_train)\n",
    "    error[i] = error_fn(y_train, y_pred)\n",
    "    i += 1\n",
    "print('*** Training error ***')\n",
    "print('N_train: '+str(N_train))\n",
    "i = 0\n",
    "for title in titles:\n",
    "    print(title+': '+str(error[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing the generalization error ###\n",
    "i = 0;\n",
    "error = np.zeros(len(titles))\n",
    "for clf in models:\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    error[i] = error_fn(y_test, y_pred_test)\n",
    "    i += 1\n",
    "print('*** Generalization error ***')\n",
    "print('N_test: '+str(N_test))\n",
    "i = 0\n",
    "for title in titles:\n",
    "    print(title+': '+str(error[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***The model is clearly overfitted!!!!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best k-rank approximation through PCA\n",
    "\n",
    "**Key questions**\n",
    "- How to efficiently apply SVD to a batch of images and make decision about the number of modes to use? \n",
    "- Do we apply SVD to each input image, each class, or to the training dataset as a whole?\n",
    "- What could be the optimum number of principal components to use? Which metric do we use to compare them?\n",
    "- Training the model with the reduced components turned out to be much more computationall y expensive than training with the raw images. Why???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA();\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)  #Note that the max number of singular values is the number of images in X_train\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cumsum, linewidth=3)\n",
    "#plt.axis([0, 400, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([d, d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "#plt.annotate(\"Elbow\", xy=(65, 0.85), xytext=(70, 0.7),\n",
    "#             arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.8)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_train_recovered = pca.inverse_transform(X_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing some of the data\n",
    "idx = 100;\n",
    "X_sample = X_train_recovered[idx].reshape(256,256);\n",
    "plt.imshow(X_sample, cmap = mpl.cm.binary); plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Projecting the rest of the data onto the PCs of the training data ###\n",
    "#Centers the data\n",
    "X_test_centered = X_test - X_test.mean(axis=0) # Test dataset\n",
    "#Extract the normal vectors of the principal components\n",
    "V_r = np.transpose(pca.components_);\n",
    "#Projects the data\n",
    "X_test_reduced = np.matmul(X_test_centered, V_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the SVM classifier on the reduced space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the models\n",
    "C = 1  # SVM regularization parameter\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.SVC(kernel='poly', degree=2, gamma='auto', C=C),\n",
    "          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C))\n",
    "titles = ('SVM with linear kernel',\n",
    "          'SVM with polynomial (degree 2) kernel',\n",
    "          'SVM with polynomial (degree 3) kernel',\n",
    "          'SVM with RBF kernel')\n",
    "#Training \n",
    "models = (clf.fit(X_train, y_train) for clf in models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0;\n",
    "error = np.zeros(len(titles))\n",
    "for clf in models:       \n",
    "    y_pred = clf.predict(X_train_reduced)\n",
    "    error[i] = error_fn(y_train, y_pred)\n",
    "    i += 1\n",
    "print('*** Training error ***')\n",
    "print('N_train: '+str(N_train))\n",
    "i = 0\n",
    "for title in titles:\n",
    "    print(title+': '+str(error[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing the generalization error ###\n",
    "i = 0;\n",
    "error = np.zeros(len(titles))\n",
    "for clf in models:\n",
    "    y_pred_test = clf.predict(X_test_reduced)\n",
    "    error[i] = error_fn(y_test, y_pred_test)\n",
    "    i += 1\n",
    "print('*** Generalization error ***')\n",
    "print('N_test: '+str(N_test))\n",
    "i = 0\n",
    "for title in titles:\n",
    "    print(title+': '+str(error[i]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced input space through random projection (maybe?)\n",
    "\n",
    "**Key questions**\n",
    "- What kind of information/improvements would we get this way compared to PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cool ways to visualize the performance of the classifier\n",
    "\n",
    "**Ideas**\n",
    "- Manually add noise/perturbations to the images to test the classfier under extreme scenarios\n",
    "- We could augment our training data set this way too! Do we need more data or are 700 images per class enough?\n",
    "- Could we extende the trained model to be interactive such that we can upload a picture and it gets classified instantly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
